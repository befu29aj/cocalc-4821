% la-06-eigen.tex

\documentclass[xcolor=dvipsnames]{beamer}
\usepackage{teachbeamer}

\title{Eigenvalues and Eigenvectors}
\subtitle{{\CourseNumber}, BCIT}

\author{\CourseName}

\date{October 29, 2018}

\begin{document}

\begin{frame}
  \titlepage
\end{frame}

\begin{frame}
  \frametitle{Motivation}
Here is a list of questions that can be answered using eigenvalues and
eigenvectors.
\begin{itemize}
\item Let the probability of rain tomorrow depend only on whether
  there is rain today. If it rains today, the probability of rain
  tomorrow is 20\%. If it is clear today, the probability of rain
  tomorrow is 10\%. What is the average ratio of rainy days to clear
  days in this climate?
\item Let a particle go on a random walk along a line between $S_{1}$
  and $S_{n}$. How much of its time does it spend at $S_{i}$?
\item The Fibonacci sequence is $1,1,2,3,5,8,13,21,34,{\ldots}$. It is
  used in many applications, for example population modeling. Is there
  an explicit (not recursive) formula for the $n$-th term?
\item Given a matrix $A$, what is $A^{n}$ for large $n$?
\item Given a matrix $B$, what is a matrix $C$ such that $C^{2}=B$?
\end{itemize}
\end{frame}

\begin{frame}
  \frametitle{Eigenvalues and Eigenvectors}
  Consider a square matrix $A$. A real (or complex) number $\lambda$
  is an \alert{eigenvalue} if and only if there exists an \alert{eigenvector}
  $X\neq{}0$ such that
  \begin{equation}
    \label{eq:raeshaez}
    AX=\lambda{}X
  \end{equation}
  $AX=\lambda{}X$ is equivalent to the system of linear equations
  $(A-\lambda{}I)X=0$, which has a non-zero solution if and only if
  $A-\lambda{}I$ is singular,
\begin{equation}
  \label{eq:aeshopae}
  \det(A-\lambda{}I)=0
\end{equation}
$\det(A-\lambda{}I)$ is a polynomial in $\lambda$. It is called the
\alert{characteristic polynomial}.
\end{frame}

\begin{frame}
  \frametitle{Eigenvalues and Eigenvectors}
  \begin{block}{Characteristic Polynomial}
    The eigenvalues of a square matrix $A$ are the roots (solutions)
    of the polynomial equation $\det(A-\lambda{}I)=0$.
  \end{block}

  \bigskip

  {\ubung} Find the eigenvalues of
  \begin{equation}
    \label{eq:neevicuo}
    A=\left[
      \begin{array}{cc}
        3&-1\\
        2&0
      \end{array}\right]
  \end{equation}
and find one eigenvector for each eigenvalue.
\end{frame}

\begin{frame}
  \frametitle{Eigenvalues and Eigenvectors}
  Solution: find the determinant of
  \begin{equation}
    \label{eq:aeboapai}
    A-\lambda{}I=\left[
      \begin{array}{cc}
        3-\lambda&-1\\
        2&-\lambda
      \end{array}\right]
  \end{equation}
The characteristic polynomial is $\lambda^{2}-3\lambda+2$. The
eigenvalues of $A$ are $\lambda=2$ and $\lambda=1$. Now solve the
systems of linear equations for the eigenvectors:
\begin{equation}
  \label{eq:ahquaiwi}
  (A-2I)X=0\mbox{ for }\lambda=2
\end{equation}
and
\begin{equation}
  \label{eq:eetoodai}
  (A-I)X=0\mbox{ for }\lambda=1
\end{equation}
\end{frame}

\begin{frame}
  \frametitle{Eigenvalues and Eigenvectors}
  \begin{equation}
    \label{eq:jaegheed}
    A-2I=\left[
      \begin{array}{cc}
        1&-1\\
        2&-2
      \end{array}\right]\sim\left[
      \begin{array}{cc}
        1&-1\\
        0&0
      \end{array}\right]
  \end{equation}
  The solution set is
  \begin{equation}
    \label{eq:enahvodo}
S=\left\{X\in\mathbb{R}^{2}\;|\;X=s_{1}\left(
    \begin{array}{c}
      1\\
      1
    \end{array}\right),s_{1}\in\mathbb{R}\right\}
\end{equation}
$S$ is called the \alert{eigenspace} of $\lambda=2$. All vectors
except $X=0$ in the eigenspace of $\lambda$ are called eigenvectors
belonging to $\lambda$. Find the eigenspace of $\lambda=1$.
\end{frame}

\begin{frame}
  \frametitle{Eigenvalues and Eigenvectors}
  {\ubung} Find the eigenvalues and associated eigenvectors for
  \begin{equation}
    \label{eq:liezaiba}
    A=\left[
      \begin{array}{ccc}
        2&4&2 \\
        0&-3&-1 \\
        0&0&0
      \end{array}\right]
  \end{equation}
\end{frame}

\begin{frame}
  \frametitle{Eigenvalues and Eigenvectors}
  Suppose $\{V_{1},{\ldots},V_{n}\}$ is a basis for $\mathbb{R}^{n}$
  and that each of these is an eigenvector for an $n\times{}n$ matrix
  $A$. $\{V_{1},{\ldots},V_{n}\}$ is called an \alert{eigenbasis} with
  respect to $A$. Thus, we can write
  \begin{equation}
    \label{eq:chucarie}
    AV_{1}=\lambda_{1}V_{1},{\ldots},AV_{n}=\lambda_{n}V_{n}
  \end{equation}
where $\lambda_{1},{\ldots},\lambda_{n}$ are the eigenvalues. Let $P$
be the matrix whose columns are the basis vectors
$\{V_{1},{\ldots},V_{n}\}$. Then
\begin{equation}
  \label{eq:ahzieyuc}
  P^{-1}AP=\left[
    \begin{array}{cccc}
      \lambda_{1}&0&\ldots&0 \\
      0&\lambda_{2}&\ldots&0 \\
      \vdots & \vdots & \ddots & \vdots \\
      0 & 0 & \ldots & \lambda_{n}
    \end{array}\right]
\end{equation}
This matrix $D$ is called a \alert{diagonal form} of $A$.
% Proof: Paul C. Shields, 282
\end{frame}

\begin{frame}
  \frametitle{Eigenvalues and Eigenvectors}
  Not every $n\times{}n$ matrix $A$ generates an eigenbasis. There is
  a theorem in linear algebra that tells us that such an eigenbasis is
  available if the characteristic polynomial has $n$ distinct real
  roots.

  \bigskip

  Another theorem of linear algebra tells us that symmetric matrices
  have an associated eigenbasis. A matrix $A$ is symmetric if and only
  if $A=A^{\intercal}$.

  \bigskip

  {\ubung} Find a diagonal form $D$ and an eigenbasis $P$ for the matrix
  \begin{equation}
    \label{eq:nohyaesu}
    A=\left[
      \begin{array}{cc}
        22&20 \\
        -25&-23
      \end{array}\right]
  \end{equation}
  and show that $P^{-1}AP=D$.
\end{frame}

\begin{frame}
  \frametitle{Similarity}
  \begin{block}{Similar Matrices}
    $A$ and $B$ are called \alert{similar} if
    \begin{equation}
      \label{eq:aemiezef}
      B=P^{-1}AP\notag
    \end{equation}
    for some matrix $P$. 
  \end{block}

  \bigskip
  
Similar matrices will have similar powers, transposes, and inverses,
and will have equal determinants and characteristic polynomials.
\end{frame}

\begin{frame}
  \frametitle{Similarity}
  If $B=P^{-1}AP$, then $B^{k}=P^{-1}A^{k}P$ for any positive integer
  $k$ (show this for $k=2$ and then think about how the idea
  generalizes).

  \bigskip

  {\ubung} Find $A^{5}$ for
  \begin{equation}
    \label{eq:aisejiez}
    A=\left[
      \begin{array}{cc}
        19&-12 \\
        24&-15
      \end{array}\right]
  \end{equation}
  The solution is
  \begin{equation}
    \label{eq:pheishae}
    A^{5}=\left[
      \begin{array}{cc}
        2179&-1452 \\
        2904&-1935
      \end{array}\right]
  \end{equation}
\end{frame}

\begin{frame}
  \frametitle{Similarity}
  {\ubung} Find a matrix $C$ such that $C^{2}=A$, where
  \begin{equation}
    \label{eq:phaithee}
    A=\left[
      \begin{array}{cc}
        3&-1 \\
        2&0
      \end{array}\right]
  \end{equation}
\end{frame}

\begin{frame}
  \frametitle{Similarity}
  If $B=P^{-1}AP$, then $\det{}B=\det{}A$. To show this, you may
  remember that $\det{}(GH)=\det{}G\cdot\det{}H$. Therefore
  \begin{equation}
    \label{eq:taichahh}
    \det{}B=\det(P^{-1}AP)=\det{}P^{-1}\det{}A\det{}P=\notag
  \end{equation}
  \begin{equation}
    \label{eq:ielaemiy}
    \det{}A\det{}P^{-1}\det{}P=\det{}A\det(P^{-1}P)=\det{}A\notag
  \end{equation}
\end{frame}

\begin{frame}
  \frametitle{End of Lesson}
Next Lesson: Axioms and Theorems of Probability
\end{frame}

\end{document}
